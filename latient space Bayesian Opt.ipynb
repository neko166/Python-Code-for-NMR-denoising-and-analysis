{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler,LabelEncoder\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import mean_squared_error as MSE\n",
    "from sklearn.ensemble import RandomForestRegressor as RFR\n",
    "\n",
    "from functools import partial\n",
    "from bayes_opt import BayesianOptimization\n",
    "import random\n",
    "\n",
    "import tensorflow as tf\n",
    "from keras.layers import (Dense,Conv1D,BatchNormalization,GlobalAveragePooling1D\n",
    "                          ,MaxPooling1D,AveragePooling1D,Multiply,Add)\n",
    "\n",
    "from tensorflow.keras.models import model_from_json\n",
    "from define_CNN_class import MyResNetModel\n",
    "from define_CNN_class import ResidualBlock\n",
    "from define_CNN_class import NoiseGate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ニューラルネットワークを宣言"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_objects={\n",
    "        'MyResNetModel': MyResNetModel,\n",
    "        'ResidualBlock':ResidualBlock,\n",
    "        'NoiseGate':NoiseGate        \n",
    "        }\n",
    "\n",
    "with open(r'cnn_model_structual_data.json', 'r') as json_file:\n",
    "\n",
    "    json_string = json_file.read()\n",
    "    model = model_from_json(json_string,custom_objects=custom_objects)\n",
    "\n",
    "\n",
    "model.load_weights(r\"cnn_model.weights.h5\")\n",
    "model.summary()\n",
    "model.compile(optimizer='adam', loss='mse')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1= pd.read_excel(r\"PKSP_Q84mse(25,40,55)v2.xlsx\",sheet_name=\"解析用平均値\",header=1)\n",
    "df1_X=df1[df1['Temp'] == 298]\n",
    "df1_X=df1_X[df1['サンプルNo.'] >=17]\n",
    "NMR_columns=df1_X.columns[10:320]\n",
    "\n",
    "NMR_data=df1_X.copy().loc[:,NMR_columns]\n",
    "\n",
    "for i in range(len(NMR_data)):\n",
    "    data=NMR_data.iloc[i,:].copy()\n",
    "    NMR_data.iloc[i,:]= (data-np.min(data))/(np.max(data)-np.min(data))\n",
    "    #Nomalized_data.iloc[i,:]= data/np.max(data)\n",
    "\n",
    "    #print(np.max(Nomalized_data.iloc[i,:]))\n",
    "    #print(np.min(Nomalized_data.iloc[i,:]))\n",
    "\n",
    "process_columns=df1_X.columns[2:6]#成型条件が格納されているcolumnを取得\n",
    "process_data=df1_X.copy().loc[:,process_columns]#columnをもとにNMRデータを取得\n",
    "\n",
    "#print(NMR_data)\n",
    "\n",
    "index=[]\n",
    "for i in range(len(NMR_data)):\n",
    "    index.append(f\"Q{i+17}-MSE-298-1\")#サンプル番号、パルス名、温度、N番号\n",
    "\n",
    "NMR_data.index=index\n",
    "#print(NMR_data)\n",
    "\n",
    "physics_data=pd.read_csv(r\"物性のデータ.csv\").loc[:,\"y1\":]\n",
    "physics_data.index=index\n",
    "process_data.index=index\n",
    "print(physics_data)\n",
    "print(process_data)\n",
    "\n",
    "for i in range(4):\n",
    "    le=LabelEncoder()\n",
    "    le.fit(process_data.iloc[:,i])\n",
    "    process_data.iloc[:,i]=le.transform(process_data.iloc[:,i])\n",
    "    print(np.max( process_data.iloc[:,i]))\n",
    "\n",
    "print(process_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred=[]\n",
    "soft_noise=[]\n",
    "\n",
    "CNN_smooth=pd.DataFrame()\n",
    "CNN_gap=pd.DataFrame()\n",
    "ave_smooth=pd.DataFrame()\n",
    "\n",
    "for i in range(len(NMR_data)):\n",
    "    #data=model.predict(average_smoothing(np.array(selected_MAPE_data.loc[f\"Q1{i}-mape-298-1\",:]).reshape(1,311,1),num=10)).reshape(-1)\n",
    "    pred=model.predict(np.array(NMR_data.iloc[i,:]).reshape(1,310,1))\n",
    "                       \n",
    "    data,gap=pred[0].reshape(-1),pred[1].reshape(-1)#出力を取得\n",
    "    CNN_smooth[f\"Q{i+17}-MSE-298-1\"]=data\n",
    "    CNN_gap[f\"Q{i+17}-MSE-298-1\"]=gap\n",
    "    #サンプル番号、パルス名、温度、N番号をラベルにする\n",
    "\n",
    "    \n",
    "CNN_smooth=CNN_smooth.T\n",
    "CNN_gap=CNN_gap.T\n",
    "\n",
    "CNN_gap.columns=[f\"gap_{i}\" for i in range(len(CNN_gap.columns))]\n",
    "#ave_smooth=ave_smooth.T\n",
    "\n",
    "CNN_smooth.columns=columns=np.arange(310)*0.00064\n",
    "\n",
    "print(CNN_smooth.shape)\n",
    "print(CNN_smooth)\n",
    "\n",
    "\n",
    "print(CNN_gap.shape)\n",
    "print(CNN_gap)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SS_X=StandardScaler()\n",
    "ss_physics_data=pd.DataFrame(SS_X.fit_transform(physics_data),index=physics_data.index,columns=physics_data.columns)\n",
    "\n",
    "SS_X=StandardScaler()\n",
    "ss_CNN_gap=pd.DataFrame(SS_X.fit_transform(CNN_gap),index=CNN_gap.index,columns=CNN_gap.columns)\n",
    "\n",
    "\n",
    "process_physics_gap=pd.concat([process_data,ss_physics_data,ss_CNN_gap],axis=1)\n",
    "print(process_physics_gap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1= pd.read_excel(r\"PKSP_Q84mse(25,40,55)v2.xlsx\",sheet_name=\"解析用平均値\",header=1)\n",
    "df1_X=df1[df1['Temp'] == 298]\n",
    "df1_X=df1_X[df1['サンプルNo.'] >=17]\n",
    "NMR_columns=df1_X.columns[10:320]#NMRデータが格納されているcolumnを取得\n",
    "NMR_data=df1_X.copy().loc[:,NMR_columns]#columnをもとにNMRデータを取得\n",
    "\n",
    "for i in range(len(NMR_data)):\n",
    "    data=NMR_data.iloc[i,:].copy()#安全のため一行ずつコピーを生成\n",
    "    CNN_smooth.iloc[i,:]=(CNN_smooth.iloc[i,:].copy()*((np.max(data)-np.min(data))))+np.min(data)#正規化されていたデータを元に戻す\n",
    "\n",
    "print(CNN_smooth)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(np.array(CNN_gap.iloc[:,0]).reshape(-1).shape)\n",
    "print(physics_data[f\"y1\"].shape)\n",
    "\n",
    "SS_X=StandardScaler()\n",
    "SS_X.fit((CNN_gap))\n",
    "ss_gap=pd.DataFrame(SS_X.transform((CNN_gap)))\n",
    "\n",
    "\n",
    "target_gap_list=[]\n",
    "for i in range(1,10,1):\n",
    "    print(f\"y{i}\")\n",
    "    max_score=0\n",
    "    index_num=0\n",
    "    SS_Y=StandardScaler()\n",
    "    SS_Y.fit(np.array(physics_data[f\"y{i}\"]).reshape(-1,1))\n",
    "    y_data=SS_Y.transform(np.array(physics_data[f\"y{i}\"]).reshape(-1,1))\n",
    "    \n",
    "    num=64\n",
    "\n",
    "    for j in range(256):\n",
    "        score=np.corrcoef(np.array(ss_gap.iloc[0:num,j]).reshape(-1),y_data[0:num].reshape(-1))[0,1]\n",
    "        if (score)>abs(max_score):\n",
    "            max_score=(score)\n",
    "            index_num=j\n",
    "      \n",
    "        #print(np.corrcoef(np.array(CNN_gap.iloc[:,j]).reshape(-1),y_data.reshape(-1)))\n",
    "\n",
    "    print(index_num)\n",
    "    print(max_score)\n",
    "\n",
    "    target_gap_list.append(f\"gap_{index_num}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SS_X=StandardScaler()\n",
    "ss_physics_data=pd.DataFrame(SS_X.fit_transform(physics_data),index=physics_data.index,columns=physics_data.columns)\n",
    "\n",
    "SS_X=StandardScaler()\n",
    "ss_CNN_gap=pd.DataFrame(SS_X.fit_transform(CNN_gap),index=CNN_gap.index,columns=CNN_gap.columns)\n",
    "\n",
    "\n",
    "process_physics_gap=pd.concat([process_data,ss_physics_data,ss_CNN_gap],axis=1)\n",
    "print(process_physics_gap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(process_physics_gap.iloc[:,:5].head())\n",
    "\n",
    "\n",
    "# BaysianOptimizationで最適化する関数を定義する\n",
    "# 結晶化温度/℃ ,結晶化時間 ,核材の濃度/％ ,冷結晶化の4要素を指定させる\n",
    "#入力は任意の実数で関数内で離散的な実現値に変換する\n",
    "#実現値でprocess_dataのDataFrameを探索して行名or行番号を取得\n",
    "#取得した行番号で物性値 or GAPのDataFrameを検索してreturn\n",
    "def pick_up(crystallize_temp ,crystallize_length ,per_nucleating_agent ,cold_crystallize,process_physics_gap ,search_columns):\n",
    "\n",
    "    crystallize_temp = int(crystallize_temp)#実数で渡された値を離散化\n",
    "    crystallize_length = int(crystallize_length)\n",
    "    per_nucleating_agent = int(per_nucleating_agent)\n",
    "    cold_crystallize = int(cold_crystallize)\n",
    "    \n",
    "    data = process_physics_gap.set_index(['結晶化温度/℃', '結晶化時間', '核材の濃度/％', '冷結晶化'])#カラム名を複合キーに指定する\n",
    "    key=(crystallize_temp,crystallize_length,per_nucleating_agent,cold_crystallize)#関数に渡された値で検索をかける\n",
    "    \n",
    "    if key in data.index:\n",
    "        result = data.loc[key,f\"{search_columns}\"]\n",
    "    else:\n",
    "        result = 0 #複合キーに網羅性がないため、実現しない値での検索が起こった場合の例外処理として0を返すようにする\n",
    "\n",
    "    return result\n",
    "\n",
    "\n",
    "rocked_pick_up = partial(pick_up,process_physics_gap=process_physics_gap,search_columns=\"y1\")\n",
    "#一部の変数を固定して代入できるようにする\n",
    "\n",
    "#print(rocked_pick_up(1,1,1,0))\n",
    "print(rocked_pick_up(crystallize_temp=1 ,crystallize_length=1 ,per_nucleating_agent=1 ,cold_crystallize=0))\n",
    "\n",
    "\n",
    "\n",
    "df_target_names=pd.DataFrame()\n",
    "df_target_names[\"y\"]=[f\"y{i}\" for i in range(1,10,1)]\n",
    "df_target_names[\"gap\"]=target_gap_list\n",
    "df_target_names.index=range(1,10,1)\n",
    "print(df_target_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_target_names=pd.DataFrame()\n",
    "df_target_names[\"y\"]=[f\"y{i}\" for i in range(1,10,1)]\n",
    "df_target_names[\"gap\"]=target_gap_list\n",
    "df_target_names.index=range(1,10,1)\n",
    "print(df_target_names)\n",
    "\n",
    "\n",
    "# BaysianOptimizationで最適化する関数を定義する\n",
    "# 結晶化温度/℃ ,結晶化時間 ,核材の濃度/％ ,冷結晶化の4要素を指定させる\n",
    "#入力は任意の実数で関数内で離散的な実現値に変換する\n",
    "#実現値でprocess_dataのDataFrameを探索して行名or行番号を取得\n",
    "#取得した行番号で物性値 or GAPのDataFrameを検索してreturn\n",
    "#def pick_up(crystallize_temp ,crystallize_length ,per_nucleating_agent ,cold_crystallize,process_physics_gap ,search_columns):\n",
    "def pick_up(crystallize_temp ,crystallize_length ,per_nucleating_agent ,process_physics_gap ,search_columns):\n",
    "\n",
    "    crystallize_temp = int(crystallize_temp)#実数で渡された値を離散化\n",
    "    crystallize_length = int(crystallize_length)\n",
    "    per_nucleating_agent = int(per_nucleating_agent)\n",
    "    #cold_crystallize = int(cold_crystallize)\n",
    "    cold_crystallize=0 #冷結晶化のデータを除外するかどうかは要検討\n",
    "\n",
    "    data = process_physics_gap.set_index(['結晶化温度/℃', '結晶化時間', '核材の濃度/％', '冷結晶化'])#カラム名を複合キーに指定する\n",
    "    key=(crystallize_temp,crystallize_length,per_nucleating_agent,cold_crystallize)#関数に渡された値で検索をかける\n",
    "    \n",
    "    if key in data.index:\n",
    "        result = data.loc[key,f\"{search_columns}\"]\n",
    "    else:\n",
    "        result = 0 #複合キーに網羅性がないため、実現しない値での検索が起こった場合の例外処理として0を返すようにする\n",
    "\n",
    "    return result\n",
    "\n",
    "\n",
    "df_result_list=[]#各回の試行の結果をまとめたDataFrameを保存する配列\n",
    "\n",
    "for k in range(200):\n",
    "    print(f\"{k}周目\")\n",
    "    df_result=pd.DataFrame()\n",
    "    random_state=42 + k #疑似乱数のシード値にkを足して各実験の初回探索が変わるようにする\n",
    "\n",
    "    #物性値とGAPで網羅的に探索\n",
    "    for i in range(1,len(df_target_names)+1,1):# 9行分\n",
    "        for j  in df_target_names.columns: #2列分(yiとgap)を探索する\n",
    "\n",
    "            target=df_target_names.loc[i,j]\n",
    "            rocked_pick_up = partial(pick_up, process_physics_gap = process_physics_gap, search_columns = target)\n",
    "            #一部の変数を固定して代入できるようにする\n",
    "\n",
    "\n",
    "            #ベイズ最適化で探索するパラメータ空間を定義する\n",
    "            process_bo = BayesianOptimization(\n",
    "                f=rocked_pick_up,  #最適化する関数\n",
    "                pbounds={\n",
    "                    'crystallize_temp': (-0.5, 0.5+np.max(process_physics_gap[\"結晶化温度/℃\"])),#int型で離散化するため、探索対象の最大値＋0.99の値域を与えてほぼ均等に網羅性を確保\n",
    "                    'crystallize_length': (-0.5, 0.5+np.max(process_physics_gap[\"結晶化時間\"])),\n",
    "                    'per_nucleating_agent': (-0.5, 0.5+np.max(process_physics_gap[\"核材の濃度/％\"]))\n",
    "                },\n",
    "                random_state=random_state #初回探索の対象を決める疑似乱数のシード値\n",
    "                )\n",
    "\n",
    "            #ベイズ最適化を実行（scoreが最大となるようにパラメータを探索していく）\n",
    "\n",
    "\n",
    "            process_bo.maximize(init_points=20, n_iter=100)\n",
    "\n",
    "            #試行した全課程の情報を取得\n",
    "            all_trials = process_bo.res\n",
    "            print(all_trials)\n",
    "\n",
    "            trials_df = pd.DataFrame([{\n",
    "                **trial['params'],   # 各試行のパラメータ\n",
    "                f'{target}': trial['target']  # 試行結果のスコア\n",
    "            } for trial in all_trials])\n",
    "\n",
    "\n",
    "            print(trials_df)\n",
    "            if \"y\" in target:\n",
    "                df_result[target]=trials_df[target]\n",
    "                \n",
    "            elif \"gap\" in target:\n",
    "                df_result[f\"y{i}_{target}\"]=[pick_up(**trial['params'],process_physics_gap=process_physics_gap,search_columns=f\"y{i}\") for trial in all_trials]\n",
    "            \n",
    "            print(df_result)\n",
    "            \n",
    "    df_result_list.append(df_result)\n",
    "        \n",
    "#実際に調べた有効なサンプル数を表示する\n",
    "\n",
    "print(\"y1\")\n",
    "print(np.max(df_result_list[0][\"y1\"]))\n",
    "print(np.max(df_result_list[0][\"y1_gap_240\"]))\n",
    "\n",
    "print(\"y2\")\n",
    "print(np.max(df_result_list[0][\"y2\"]))\n",
    "print(np.max(df_result_list[0][\"y2_gap_113\"]))\n",
    "\n",
    "print(\"y3\")\n",
    "print(np.max(df_result_list[0][\"y3\"]))\n",
    "print(np.max(df_result_list[0][\"y3_gap_240\"]))\n",
    "\n",
    "print(\"y4\")\n",
    "print(np.max(df_result_list[0][\"y4\"]))\n",
    "print(np.max(df_result_list[0][\"y4_gap_240\"]))\n",
    "\n",
    "print(\"y5\")\n",
    "print(np.max(df_result_list[0][\"y5\"]))\n",
    "print(np.max(df_result_list[0][\"y5_gap_178\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i  in range(1,10,1):\n",
    "    print(np.max(process_physics_gap[f\"y{i}\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r2_score_list=[]\n",
    "#物性ごとに実験の平均値を表示\n",
    "for i in range(9):#物性の数\n",
    "    df_random_search=pd.DataFrame()\n",
    "\n",
    "    #空のDataFrameを宣言\n",
    "    df_bo_improve_max_y=pd.DataFrame()\n",
    "    df_bo_improve_max_gap=pd.DataFrame()\n",
    "    for j in range(200):#実験回数\n",
    "       \n",
    "\n",
    "        random_search=[pick_up(crystallize_temp=random.uniform(-0.5, 0.5+np.max(process_physics_gap[\"結晶化温度/℃\"])) ,crystallize_length=random.uniform(-0.5, 0.5+np.max(process_physics_gap[\"結晶化時間\"])) ,per_nucleating_agent=random.uniform(-0.5, 0.5+np.max(process_physics_gap[\"核材の濃度/％\"])) ,process_physics_gap=process_physics_gap ,search_columns=f\"y{i+1}\") for _ in range(120)]\n",
    "        df_random_search[j]=[np.max(random_search[:k+1]) for k in range(120)]\n",
    "\n",
    "\n",
    "\n",
    "        #それぞれの実験のmaxの推移を表現した配列をリスト内包表記で作成\n",
    "        df_bo_improve_max_y[j]=[np.max(df_result_list[j].iloc[:k+1,i*2]) for k in range(len(df_result))]\n",
    "        df_bo_improve_max_gap[j]=[np.max(df_result_list[j].iloc[:k+1,i*2+1]) for k in range(len(df_result))]\n",
    "\n",
    "    #リス他内包表記で行ごとの平均値を配列に変換\n",
    "    print(f\"y{i+1}\")\n",
    "    #print(np.max(df_result_list.iloc[:,i*2]))\n",
    "    #print(np.max(df_result_list.iloc[:,i*2+1]))\n",
    "\n",
    "    \n",
    "    plt.plot(range(len(df_result)),[np.mean(df_bo_improve_max_y.iloc[j,:]) for j in range(len(df_result))],label=\"y\")\n",
    "    plt.plot(range(len(df_result)),[np.mean(df_bo_improve_max_gap.iloc[j,:]) for j in range(len(df_result))],label=\"gap\")\n",
    "    plt.plot(range(len(df_result)),[np.mean(df_random_search.iloc[j,:]) for j in range(len(df_result))],label=\"random\")\n",
    "\n",
    "    plt.plot(range(len(df_result)),[np.max(process_physics_gap[f\"y{i+1}\"]) for j in range(len(df_result))],label=\"max\",color=\"black\")\n",
    "\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    print(\"gap\",r2_score([np.mean(df_bo_improve_max_y.iloc[j,:]) for j in range(len(df_result))],[np.mean(df_bo_improve_max_gap.iloc[j,:]) for j in range(len(df_result))]))\n",
    "    print(\"random:\",r2_score([np.mean(df_bo_improve_max_y.iloc[j,:]) for j in range(len(df_result))],[np.mean(df_random_search.iloc[j,:]) for j in range(len(df_result))]))\n",
    "\n",
    "    r2_score_list.append(r2_score([np.mean(df_bo_improve_max_y.iloc[j,:]) for j in range(len(df_result))],[np.mean(df_bo_improve_max_gap.iloc[j,:]) for j in range(len(df_result))]))\n",
    "\n",
    "plt.bar(range(len(r2_score_list)),r2_score_list)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
